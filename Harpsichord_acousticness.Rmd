---
title: "Spotify Harpsichord Instrumentalness"
author: "Noah Jaffe"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(remotes)
library(spotifyr)
library(ggplot2)
spotifyr::get_spotify_access_token()

bach_harpsichord_labels = c('', '', '', '', '', 
                         '', '', '', '', 'Harpsichord - Pinnock',
                         '', '', '', '', '',
                         '', '', '', '', '',
                         '', '', '', '', '', '', '', '',
                         'Harpsichord - Beauséjour', 'Massage - Vocals', '')

```
## About the corpus  
As a curiosity, I created a playlist containing only tracks of the same piece of music:  
The C-major prelude (BWV 846) from Bach's Well Tempered Clavier, Book 1.     
<https://open.spotify.com/playlist/4yNYY3xmNhPTDrfFc0qG9b?si=5a035a14f9924ae3>

This playlist contains 29 tracks. Two of these recordings are using harpsichord. 
The two harpsichord tracks are by [Trevor Pinnock](https://open.spotify.com/track/3pbZ0GbDAl8ehNiW58wOLO?si=a10bdc71980b402b) and [Luc Beauséjour](https://open.spotify.com/track/13zyfbzt2PiYo2RjjJMCsb?si=882dc21b84d049be).

To my ears, these performances are quite similar. The tunings are slightly different, as are the performance styles. But in general, they are quite similar. The microphone and audio mixing techniques of the Pinnock recording seem more luxurious to my ears, but I cannot think of any other dissimilarities.

Finally, I found a track on the album [Sounds for Massages](https://open.spotify.com/track/1TJSjNBt6oIHV8QdgdgrBT?si=1b43d60d1f024c00) which contains the piece performed on piano, with a synthesized vocal track of "aah" placed on top. 

## Spotify API definition of acousticness and instrumentalness
The [Spotify API definition](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features) of acousticness:

### Acousticness
A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.

### Instrumentalness
Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.

## Getting the playlist track features
```{r download_features}
bach_prelude_playlist_features = get_playlist_audio_features("", "4yNYY3xmNhPTDrfFc0qG9b")
bach_prelude_playlist_features = bach_prelude_playlist_features %>% 
  mutate(track.duration_min = track.duration_ms/1000/60)  # Create duration by minute.
```

### Plot the acousticness
```{r acousticness}
acoustic_v_duration = ggplot(bach_prelude_playlist_features, aes(
  x=track.duration_min, y=acousticness,
)) + geom_point() + xlab("Track Duration (min)") + ylab("Acousticness") +
  geom_text(
    label=bach_harpsichord_labels, nudge_x=0, nudge_y=-0.02
  ) + ggtitle("Acousticness vs Track Duration") + ylim(0, 1)
acoustic_v_duration
```

### Plot the instrumentalness
```{r instrumentalness}
instrumental_v_duration = ggplot(bach_prelude_playlist_features, aes(
  x=track.duration_min, y=instrumentalness,
)) + geom_point() + xlab("Track Duration (min)") + ylab("Instrumentalness") +
  geom_text(
    label=bach_harpsichord_labels, nudge_x=0, nudge_y=-0.02
  ) + ggtitle("Instrumentalness vs Track Duration") + ylim(0, 1)
instrumental_v_duration
```

## Questions about acousticness and instrumentalness

### Instrumentalness and the tale of two harpsichords
Why does the SpotifyAPI think that Trevor Pinnock's recording sounds like it has vocals?! A score of 0.1 means that the API is quite certain that the there is vocal content. It's clear that Harpsichords have a rich harmonic content. Is it because of fancy microphone techniques that the low strings of his harpsichord resonate in a way different than that of Beauséjour's? Moreover, one would think that deliberately inserting an "aah" sound on top of the recording would tank the score, if that is what the algorithm is looking for! But it's clear that the massage recording is within the distribution of piano-only recordings.

### Harpsichord as the original electric instrument
The acousticness metric is quite more vague in the Spotify API, but it seems to be more related to spectral content. Distortion of an electric guitar is caused my compression. This distrotion is what gives gives electric guitar its signature bright sound. It makes sense that harpsichord sounds more similar to electric guitar than the felt tips of a piano. 
